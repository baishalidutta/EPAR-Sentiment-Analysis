{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img width=\"421\" alt=\"logo\" src=\"https://user-images.githubusercontent.com/76659596/113596851-2e5cc280-963b-11eb-8526-fb8fca9c837e.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Import Libraries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Import Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dataset = pd.read_excel(\n",
    "                '../data/sentences_with_sentiment.xlsx',\n",
    "                sheet_name='Sheet1',\n",
    "                index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### List first five rows to check how the data looks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             Sentence  Positive  Negative  \\\nID                                                                          \n1   The results in 2nd line treatment show an ORR ...         1         0   \n2   The long duration of response and high durable...         1         0   \n3   The median OS time in the updated results exce...         0         0   \n4   Therefore, the clinical benefit in 2nd line tr...         1         0   \n5   The data provided in 1st line, although prelim...         1         0   \n\n    Neutral  \nID           \n1         0  \n2         0  \n3         1  \n4         0  \n5         0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence</th>\n      <th>Positive</th>\n      <th>Negative</th>\n      <th>Neutral</th>\n    </tr>\n    <tr>\n      <th>ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>The results in 2nd line treatment show an ORR ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The long duration of response and high durable...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The median OS time in the updated results exce...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Therefore, the clinical benefit in 2nd line tr...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>The data provided in 1st line, although prelim...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### View the summary of the dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 266 entries, 1 to 266\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  266 non-null    object\n",
      " 1   Positive  266 non-null    int64 \n",
      " 2   Negative  266 non-null    int64 \n",
      " 3   Neutral   266 non-null    int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 10.4+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Check if there exists null entries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Sentence    0\nPositive    0\nNegative    0\nNeutral     0\ndtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Check how many positive comments the dataset has"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "1    160\n0    106\nName: Positive, dtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Positive'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Check how many negative comments the dataset has"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "0    230\n1     36\nName: Negative, dtype: int64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Negative'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Check how many neutral comments the dataset has"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "0    196\n1     70\nName: Neutral, dtype: int64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Neutral'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Check if the labels are mutually exclusive"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "Sentence    0\nPositive    0\nNegative    0\nNeutral     0\ndtype: int64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[(dataset['Positive'] == 1) & ((dataset['Negative'] == 1) | (dataset['Neutral'] == 1))].count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Check for only whitespace strings in Sentence column"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white_space = []  # start with an empty list\n",
    "\n",
    "for i,sent,pos,neg,neutral in dataset.itertuples():\n",
    "    if type(sent)==str and sent.isspace():\n",
    "        white_space.append(i)\n",
    "\n",
    "len(white_space)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The target columns do not contain any `null` entries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create a new column for multi-class classification\n",
    "\n",
    "Easy Algorithm:\n",
    "\n",
    "* Multiply any positive number to all the entries in `Positive` column\n",
    "* Multiply any negative number to all the entries in `Negative` column\n",
    "* Add these values together\n",
    "* If the result is as same as the positive number, the sentiment to be assigned is `Positive` in `Sentiment` column\n",
    "* If the result is as same as the negative number, the sentiment to be assigned is `Negative` in `Sentiment` column\n",
    "* If the result is 0, the sentiment to be assigned is `Neutral` in `Sentiment` column"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "dataset['Sentiment'] = dataset['Positive'] * 100 + dataset['Negative'] * (-100)\n",
    "dataset['Sentiment'] = dataset['Sentiment'].map({100: 'Positive', -100: 'Negative', 0: 'Neutral'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Check if the new column is created with the correct labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             Sentence  Positive  Negative  \\\nID                                                                          \n1   The results in 2nd line treatment show an ORR ...         1         0   \n2   The long duration of response and high durable...         1         0   \n3   The median OS time in the updated results exce...         0         0   \n4   Therefore, the clinical benefit in 2nd line tr...         1         0   \n5   The data provided in 1st line, although prelim...         1         0   \n6   Taking into account the intrinsic limitation o...         1         0   \n7   This medicinal product has been authorised und...         0         0   \n8   This means that further evidence on this medic...         0         1   \n9   The European Medicines Agency will review new ...         0         0   \n10  The CHMP considers the following measures nece...         0         1   \n11  In order to confirm the efficacy for chemother...         0         0   \n12  The final results of the study should be submi...         0         0   \n13  The CHMP considers that additional supportive ...         0         0   \n14  • PASS: German real-world cohort study should ...         0         1   \n15  The safety data collected at an earlier data c...         1         0   \n\n    Neutral Sentiment  \nID                     \n1         0  Positive  \n2         0  Positive  \n3         1   Neutral  \n4         0  Positive  \n5         0  Positive  \n6         0  Positive  \n7         1   Neutral  \n8         0  Negative  \n9         1   Neutral  \n10        0  Negative  \n11        1   Neutral  \n12        1   Neutral  \n13        1   Neutral  \n14        0  Negative  \n15        0  Positive  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence</th>\n      <th>Positive</th>\n      <th>Negative</th>\n      <th>Neutral</th>\n      <th>Sentiment</th>\n    </tr>\n    <tr>\n      <th>ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>The results in 2nd line treatment show an ORR ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The long duration of response and high durable...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The median OS time in the updated results exce...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Therefore, the clinical benefit in 2nd line tr...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>The data provided in 1st line, although prelim...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Taking into account the intrinsic limitation o...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>This medicinal product has been authorised und...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>This means that further evidence on this medic...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>The European Medicines Agency will review new ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>The CHMP considers the following measures nece...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>In order to confirm the efficacy for chemother...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>The final results of the study should be submi...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>The CHMP considers that additional supportive ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>• PASS: German real-world cohort study should ...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>The safety data collected at an earlier data c...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(15)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Verify the counts of the sentiments in the new column"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "Positive    160\nNeutral      70\nNegative     36\nName: Sentiment, dtype: int64"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Sentiment'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plot the counts of the sentiments"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:xlabel='Sentiment', ylabel='count'>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x432 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "sns.countplot(x='Sentiment', data=dataset, palette='Set1', order=['Negative', 'Neutral', 'Positive'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "According to the above counts and the count plot clearly indicate that the data is **unbalanced**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Cleaning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Convert text to lower case"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def convert_to_lower_case(text):\n",
    "    return \" \".join(text.lower() for text in text.split())\n",
    "\n",
    "dataset['Sentence'] = dataset['Sentence'].apply(lambda sentence: convert_to_lower_case(sentence))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Check if the sentences have been lower-cased"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             Sentence  Positive  Negative  \\\nID                                                                          \n1   the results in 2nd line treatment show an orr ...         1         0   \n2   the long duration of response and high durable...         1         0   \n\n    Neutral Sentiment  \nID                     \n1         0  Positive  \n2         0  Positive  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence</th>\n      <th>Positive</th>\n      <th>Negative</th>\n      <th>Neutral</th>\n      <th>Sentiment</th>\n    </tr>\n    <tr>\n      <th>ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>the results in 2nd line treatment show an orr ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>the long duration of response and high durable...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Remove punctuations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "'this medicinal product has been authorised under a so-called ‘conditional approval’ scheme'"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example sentence before removing punctuation\n",
    "\n",
    "dataset['Sentence'][7]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    return re.sub(r'[^\\w\\s]','',text)\n",
    "\n",
    "dataset['Sentence'] = dataset['Sentence'].apply(lambda sentence: remove_punctuations(sentence))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Check if the punctuations from a specific sentence with punctuation have been removed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "'this medicinal product has been authorised under a socalled conditional approval scheme'"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The same sentence after removing punctuation\n",
    "dataset['Sentence'][7]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Fix misspelled words if any"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is not expected to have any spelling mistakes in the EPARs. However, one small spelling mistake is found which is corrected below.\n",
    "\n",
    "Libraries like `TextBlob` can be used to find the spelling mistakes and correct them automatically. But, it will lead to further problems since pharmaceutical\n",
    "terminologies don't exist in `TextBlob`'s english corpus. Hence, auto-correction hasn't been applied.\n",
    "\n",
    "However, as a precaution, the data has been copied as text and manually reviewed on online spell checker to find out about any spelling mistake."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### The sentence with wrong spelling of `profile` -> `proflie`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "'although dataset of afl patients has been updated data are still considered very limited to reach firm conclusion about safety proflie'"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Sentence'][29]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def fix_misspelled_words(text):\n",
    "    mispelled_dict = {'proflie': 'profile'}\n",
    "\n",
    "    for word in mispelled_dict.keys():\n",
    "        text = text.replace(word, mispelled_dict[word])\n",
    "    return text\n",
    "\n",
    "dataset['Sentence'] = dataset['Sentence'].apply(lambda sentence: fix_misspelled_words(sentence))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### The above sentence with spelling mistake has been fixed\n",
    "`proflie` is corrected to `profile`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "'although dataset of afl patients has been updated data are still considered very limited to reach firm conclusion about safety profile'"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Sentence'][29]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Remove stopwords"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/amit/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join(x for x in text.split() if x not in stop_words)\n",
    "\n",
    "dataset['Sentence'] = dataset['Sentence'].apply(lambda sentence: remove_stopwords(sentence))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Check if the stopwords have been removed from a specific sentence containing stopwords"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "'results 2nd line treatment show orr 33 patients durable responses resulting apparent pfs plateau'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Sentence'][1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Lemmatization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Disable unnecessary pipelines to speed up"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# def lemmatise(text):\n",
    "#   doc = nlp(text)\n",
    "#   return \" \".join([token.lemma_ for token in doc])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using lemmatization or stemming in the sentiment analysis is debatable topic.\n",
    "Though it has advantages mainly reducing the corpus size/noise, it may break\n",
    "the parts of speech tagging."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# dataset['Sentence'] = dataset['Sentence'].apply(lambda sentence: lemmatise(sentence))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "X = dataset['Sentence']\n",
    "y = dataset['Sentiment']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Encode target labels in the Sentiment column for multi-class text classification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### List the target classes and associated labels from the encoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "['Negative', 'Neutral', 'Positive']"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target labels with value between 0 and n_classes-1 from left to right\n",
    "list(le.classes_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### TF-IDF vectorizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=2500, max_df=0.8, min_df=4)\n",
    "X = vectorizer.fit_transform(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train test split with result reproducibility using specified random seed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The plan is to implement few classical machine learning classifiers to check the accuracy of the model.\n",
    "Since all classical machine learning classifiers can share the same base imlementation, in this\n",
    "notebook, we are going to implement only one or two classical machine learning classifier(s) and the rest of the\n",
    "implementations will be available in the source code as python files."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Support Vector Machine (SVM)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define the SVM classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "classifier_svm = SVC(kernel = 'rbf', random_state = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Fit the SVM classifier (linear) on the training data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "SVC(random_state=0)"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_svm.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Prediction on the test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "svm_pred = classifier_svm.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluation Matrices"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Confusion Matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  0  6]\n",
      " [ 0  3 13]\n",
      " [ 0  0 31]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, svm_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Classification Report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25         7\n",
      "           1       1.00      0.19      0.32        16\n",
      "           2       0.62      1.00      0.77        31\n",
      "\n",
      "    accuracy                           0.65        54\n",
      "   macro avg       0.87      0.44      0.44        54\n",
      "weighted avg       0.78      0.65      0.57        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, svm_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Accuracy Score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, svm_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Apply k-Fold Cross Validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "accuracies = cross_val_score(estimator = classifier_svm, X = X_train, y = y_train, cv = 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Standard deviation of the accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.40\n"
     ]
    }
   ],
   "source": [
    "print(f\"{accuracies.std() * 100:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Mean accuracy score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.23%\n"
     ]
    }
   ],
   "source": [
    "print(f\"{accuracies.mean() * 100:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Grid Search"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(cv=10, estimator=SVC(random_state=0), n_jobs=-1,\n             param_grid=[{'C': [0.25, 0.5, 0.75, 1], 'kernel': ['linear']},\n                         {'C': [0.25, 0.5, 0.75, 1],\n                          'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8,\n                                    0.9],\n                          'kernel': ['rbf']}],\n             scoring='accuracy')"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = [{'C': [0.25, 0.5, 0.75, 1], 'kernel': ['linear']},\n",
    "              {'C': [0.25, 0.5, 0.75, 1], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n",
    "grid_search = GridSearchCV(estimator = SVC(kernel = 'rbf', random_state = 0),\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Best Accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.23%\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = grid_search.best_score_\n",
    "print(f\"{best_accuracy*100:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Best Parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "best_parameters = grid_search.best_params_\n",
    "print(best_parameters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Linear Support Vector Classifier\n",
    "\n",
    "Since by default, `LinearSVC` minimizes the squared hinge loss\n",
    "in comparison with SVC with a linear kernel that minimizes the regular\n",
    "hinge loss, the LinearSVC` may perform differently."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "lin_svc = LinearSVC(random_state=17)\n",
    "lin_svc.fit(X_train, y_train)\n",
    "lin_svc_pred = lin_svc.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Classification Report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.57      0.62         7\n",
      "           1       0.58      0.44      0.50        16\n",
      "           2       0.75      0.87      0.81        31\n",
      "\n",
      "    accuracy                           0.70        54\n",
      "   macro avg       0.67      0.63      0.64        54\n",
      "weighted avg       0.69      0.70      0.69        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lin_svc_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Confusion Matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  1  2]\n",
      " [ 2  7  7]\n",
      " [ 0  4 27]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, lin_svc_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Accuracy Score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7037037037037037\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, lin_svc_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculate cross-validation accuracies for `LinearSV` classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "accuracies = cross_val_score(\n",
    "                estimator = LinearSVC(random_state=10),\n",
    "                X = X,\n",
    "                y = y,\n",
    "                cv = 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Standard Deviation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.68\n"
     ]
    }
   ],
   "source": [
    "print(f\"{accuracies.std() * 100:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Mean Accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.72%\n"
     ]
    }
   ],
   "source": [
    "print(f\"{accuracies.mean() * 100:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conclusion\n",
    "\n",
    "So far the following classifiers have been evaulated:\n",
    "\n",
    "* Support Vector Machine with Gaussian and Linear Kernels\n",
    "* Linear Support Vector\n",
    "\n",
    "In the first case, the linear kernel SVM results in higher accuracy\n",
    "than the gaussian kernel. Given the result obtained in the previous\n",
    "tests, it was worth to look at the linear SVC model that uses different\n",
    "loss function than the SVM with linear kernel. And the test for the\n",
    "linear SVC resulted in better performance (`f1 score`, `precision` and\n",
    "`recall` for imbalanced dataset) for the negative and neutral\n",
    "sentiments.\n",
    "\n",
    "In the python sources, one can test many other classical machine learning\n",
    "classifiers as well as Bidirectional Long Short Term Memory (LSTM) Recurrent\n",
    "Neural Network (RNN) deep learning model.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}